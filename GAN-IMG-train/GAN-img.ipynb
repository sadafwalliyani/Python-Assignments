{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stylegan2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstylegan2\u001b[39;00m \u001b[39mimport\u001b[39;00m dnnlib\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdnnlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtflib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtflib\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m metric_base\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stylegan2'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Perceptual Path Length (PPL).\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from stylegan2 import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "\n",
    "from metrics import metric_base\n",
    "from training import misc\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "# Normalize batch of vectors.\n",
    "def normalize(v):\n",
    "    return v / tf.sqrt(tf.reduce_sum(tf.square(v), axis=-1, keepdims=True))\n",
    "\n",
    "# Spherical interpolation of a batch of vectors.\n",
    "def slerp(a, b, t):\n",
    "    a = normalize(a)\n",
    "    b = normalize(b)\n",
    "    d = tf.reduce_sum(a * b, axis=-1, keepdims=True)\n",
    "    p = t * tf.math.acos(d)\n",
    "    c = normalize(b - d * a)\n",
    "    d = a * tf.math.cos(p) + c * tf.math.sin(p)\n",
    "    return normalize(d)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "class PPL(metric_base.MetricBase):\n",
    "    def __init__(self, num_samples, epsilon, space, sampling, crop, minibatch_per_gpu, Gs_overrides, **kwargs):\n",
    "        assert space in ['z', 'w']\n",
    "        assert sampling in ['full', 'end']\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_samples = num_samples\n",
    "        self.epsilon = epsilon\n",
    "        self.space = space\n",
    "        self.sampling = sampling\n",
    "        self.crop = crop\n",
    "        self.minibatch_per_gpu = minibatch_per_gpu\n",
    "        self.Gs_overrides = Gs_overrides\n",
    "\n",
    "    def _evaluate(self, Gs, Gs_kwargs, num_gpus):\n",
    "        Gs_kwargs = dict(Gs_kwargs)\n",
    "        Gs_kwargs.update(self.Gs_overrides)\n",
    "        minibatch_size = num_gpus * self.minibatch_per_gpu\n",
    "\n",
    "        # Construct TensorFlow graph.\n",
    "        distance_expr = []\n",
    "        for gpu_idx in range(num_gpus):\n",
    "            with tf.device('/gpu:%d' % gpu_idx):\n",
    "                Gs_clone = Gs.clone()\n",
    "                noise_vars = [var for name, var in Gs_clone.components.synthesis.vars.items() if name.startswith('noise')]\n",
    "\n",
    "                # Generate random latents and interpolation t-values.\n",
    "                lat_t01 = tf.random_normal([self.minibatch_per_gpu * 2] + Gs_clone.input_shape[1:])\n",
    "                lerp_t = tf.random_uniform([self.minibatch_per_gpu], 0.0, 1.0 if self.sampling == 'full' else 0.0)\n",
    "                labels = tf.reshape(tf.tile(self._get_random_labels_tf(self.minibatch_per_gpu), [1, 2]), [self.minibatch_per_gpu * 2, -1])\n",
    "\n",
    "                # Interpolate in W or Z.\n",
    "                if self.space == 'w':\n",
    "                    dlat_t01 = Gs_clone.components.mapping.get_output_for(lat_t01, labels, **Gs_kwargs)\n",
    "                    dlat_t01 = tf.cast(dlat_t01, tf.float32)\n",
    "                    dlat_t0, dlat_t1 = dlat_t01[0::2], dlat_t01[1::2]\n",
    "                    dlat_e0 = tflib.lerp(dlat_t0, dlat_t1, lerp_t[:, np.newaxis, np.newaxis])\n",
    "                    dlat_e1 = tflib.lerp(dlat_t0, dlat_t1, lerp_t[:, np.newaxis, np.newaxis] + self.epsilon)\n",
    "                    dlat_e01 = tf.reshape(tf.stack([dlat_e0, dlat_e1], axis=1), dlat_t01.shape)\n",
    "                else: # space == 'z'\n",
    "                    lat_t0, lat_t1 = lat_t01[0::2], lat_t01[1::2]\n",
    "                    lat_e0 = slerp(lat_t0, lat_t1, lerp_t[:, np.newaxis])\n",
    "                    lat_e1 = slerp(lat_t0, lat_t1, lerp_t[:, np.newaxis] + self.epsilon)\n",
    "                    lat_e01 = tf.reshape(tf.stack([lat_e0, lat_e1], axis=1), lat_t01.shape)\n",
    "                    dlat_e01 = Gs_clone.components.mapping.get_output_for(lat_e01, labels, **Gs_kwargs)\n",
    "\n",
    "                # Synthesize images.\n",
    "                with tf.control_dependencies([var.initializer for var in noise_vars]): # use same noise inputs for the entire minibatch\n",
    "                    images = Gs_clone.components.synthesis.get_output_for(dlat_e01, randomize_noise=False, **Gs_kwargs)\n",
    "                    images = tf.cast(images, tf.float32)\n",
    "\n",
    "                # Crop only the face region.\n",
    "                if self.crop:\n",
    "                    c = int(images.shape[2] // 8)\n",
    "                    images = images[:, :, c*3 : c*7, c*2 : c*6]\n",
    "\n",
    "                # Downsample image to 256x256 if it's larger than that. VGG was built for 224x224 images.\n",
    "                factor = images.shape[2] // 256\n",
    "                if factor > 1:\n",
    "                    images = tf.reshape(images, [-1, images.shape[1], images.shape[2] // factor, factor, images.shape[3] // factor, factor])\n",
    "                    images = tf.reduce_mean(images, axis=[3,5])\n",
    "\n",
    "                # Scale dynamic range from [-1,1] to [0,255] for VGG.\n",
    "                images = (images + 1) * (255 / 2)\n",
    "\n",
    "                # Evaluate perceptual distance.\n",
    "                img_e0, img_e1 = images[0::2], images[1::2]\n",
    "                distance_measure = misc.load_pkl('http://d36zk2xti64re0.cloudfront.net/stylegan1/networks/metrics/vgg16_zhang_perceptual.pkl')\n",
    "                distance_expr.append(distance_measure.get_output_for(img_e0, img_e1) * (1 / self.epsilon**2))\n",
    "\n",
    "        # Sampling loop.\n",
    "        all_distances = []\n",
    "        for begin in range(0, self.num_samples, minibatch_size):\n",
    "            self._report_progress(begin, self.num_samples)\n",
    "            all_distances += tflib.run(distance_expr)\n",
    "        all_distances = np.concatenate(all_distances, axis=0)\n",
    "\n",
    "        # Reject outliers.\n",
    "        lo = np.percentile(all_distances, 1, interpolation='lower')\n",
    "        hi = np.percentile(all_distances, 99, interpolation='higher')\n",
    "        filtered_distances = np.extract(np.logical_and(lo <= all_distances, all_distances <= hi), all_distances)\n",
    "        self._report_result(np.mean(filtered_distances))\n",
    "\n",
    "#----------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
