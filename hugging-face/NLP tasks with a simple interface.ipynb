{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "878076c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "# headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "# def query(payload):\n",
    "# \tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "# \treturn response.json()\n",
    "\t\n",
    "# output = query({\n",
    "# \t\"inputs\": \"I like you. I love you\",\n",
    "# })\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea49112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from IPython.display import Image, display, HTML\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# hf_api_key = os.environ['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']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe3ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "#Summarization endpoint\n",
    "def get_completion(inputs, parameters=None,ENDPOINT_URL=[\"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment\"]): \n",
    "    headers = {\n",
    "      \"Authorization\": f\"Bearer {'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'}\",\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = { \"inputs\": inputs }\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\"POST\",\n",
    "                                ENDPOINT_URL, headers=headers,\n",
    "                                data=json.dumps(data)\n",
    "                               )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "# print(get_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d8561a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# get_completion = pipeline(\"summarization\", model=\"shleifer/distilbart-cnn-12-6\")\n",
    "# Replace 'your_model_identifier' with the correct model identifier\n",
    "model_identifier = 'sshleifer/distilbart-cnn-12-6'\n",
    "api_token = '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'\n",
    "\n",
    "# Create the pipeline with the authentication token\n",
    "get_completion = pipeline(\"summarization\", model=model_identifier, revision=\"main\", token=api_token)\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7932072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "#         as an 81-storey building, and the tallest structure in Paris. \n",
    "#         Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "#         During its construction, the Eiffel Tower surpassed the Washington \n",
    "#         Monument to become the tallest man-made structure in the world,\n",
    "#         a title it held for 41 years until the Chrysler Building\n",
    "#         in New York City was finished in 1930. It was the first structure \n",
    "#         to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "#         aerial at the top of the tower in 1957, it is now taller than the \n",
    "#         Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "#         Eiffel Tower is the second tallest free-standing structure in France \n",
    "#         after the Millau Viaduct.''')\n",
    "# get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "032e74c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 89. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=44)\n",
      "Your max_length is set to 142, but your input_length is only 98. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1:  The Eiffel Tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building . Its base is square, measuring 125 metres (410 ft) on each side . The tower is located on the Champ de Mars in Paris, France .\n",
      "Summary 2:  The Eiffel Tower is one of the most famous landmarks in the world . It was originally built as a temporary structure for the 1889 World's Fair . The tower is visited by millions of tourists each year, and offers stunning views of the city from its observation decks .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model_identifier)\n",
    "\n",
    "text = [\n",
    "    '''The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "       as an 81-storey building, and the tallest structure in Paris.\n",
    "       Its base is square, measuring 125 metres (410 ft) on each side.\n",
    "       The Eiffel Tower is located on the Champ de Mars in Paris, France.''',\n",
    "    '''The Eiffel Tower is one of the most famous landmarks in the world.\n",
    "       It was originally built as a temporary structure for the 1889 World's Fair,\n",
    "       but it has since become a permanent symbol of Paris and France.\n",
    "       The tower is visited by millions of tourists each year, and it offers\n",
    "       stunning views of the city from its observation decks.'''\n",
    "]\n",
    "\n",
    "# Summarize the input text\n",
    "summary_output = summarizer(text)\n",
    "\n",
    "# Print the summaries\n",
    "for i, output in enumerate(summary_output):\n",
    "    print(f\"Summary {i + 1}: {output['summary_text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21b741",
   "metadata": {},
   "source": [
    "Getting started with Gradio gr.Interface\n",
    "How about running it locally?\n",
    "The code would look very similar if you were running it locally. Simply remove all the paramters in the launch method\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69db60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "    \n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize, inputs=[gr.Textbox(label='Text to summarize')],\n",
    "                    outputs=[gr.Textbox(label='Results')])\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4ca6d",
   "metadata": {},
   "source": [
    "You can add demo.launch(share=True) to create a public link to share with your team or friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "793f2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\gradio\\utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Local\\Temp\\ipykernel_20440\\4281735934.py\", line 4, in summarize\n",
      "    output = get_completion(input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 265, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 165, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 1122, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 1129, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 1028, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 187, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py\", line 1282, in generate\n",
      "    self._validate_model_kwargs(model_kwargs.copy())\n",
      "  File \"C:\\Users\\Sadaf\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py\", line 1155, in _validate_model_kwargs\n",
      "    raise ValueError(\n",
      "ValueError: The following `model_kwargs` are not used by the model: ['token'] (note: typos in the generate arguments will also show up in this list)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0]['summary_text']\n",
    "    \n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=summarize, \n",
    "                    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "                    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "                    title=\"Text summarization with Sadaf Walliyani-cnn\",\n",
    "                    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\"\n",
    "                   )\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "297a7974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ebd9f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d43f948e11841e1b3804d3ec1475aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e468c4ca79e645e2b6afb0536302298a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508e69cafc934fc5a39e3f7690cf27ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce2c0b38c6a4fd5abc0ceed8cd809ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acc127984fd41d884f9172e1ffdd04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Label: LABEL_1\n",
      "Sentiment Score: 0.6198556423187256\n"
     ]
    }
   ],
   "source": [
    "API_URL = ['https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment'] #NER endpoint\n",
    "# text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "# get_completion(text, parameters=None, ENDPOINT_URL= API_URL)\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "\n",
    "# Perform sentiment analysis on the input text\n",
    "sentiment_output = sentiment_analyzer(text)\n",
    "\n",
    "# Print the sentiment label and score\n",
    "print(\"Sentiment Label:\", sentiment_output[0]['label'])\n",
    "print(\"Sentiment Score:\", sentiment_output[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7b11da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m gr\u001b[39m.\u001b[39mclose_all()\n\u001b[0;32m      6\u001b[0m demo \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mInterface(fn\u001b[39m=\u001b[39mner,\n\u001b[0;32m      7\u001b[0m                     inputs\u001b[39m=\u001b[39m[gr\u001b[39m.\u001b[39mTextbox(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mText to find entities\u001b[39m\u001b[39m\"\u001b[39m, lines\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)],\n\u001b[0;32m      8\u001b[0m                     outputs\u001b[39m=\u001b[39m[gr\u001b[39m.\u001b[39mHighlightedText(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mText with entities\u001b[39m\u001b[39m\"\u001b[39m)],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[39m#Here we introduce a new tag, examples, easy to use examples for your application\u001b[39;00m\n\u001b[0;32m     13\u001b[0m                     examples\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mMy name is Andrew and I live in California\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMy name is Poli and work at HuggingFace\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> 14\u001b[0m demo\u001b[39m.\u001b[39mlaunch(share\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, server_port\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mPORT3\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
    "                    examples=[\"My name is Andrew and I live in California\", \"My name is Poli and work at HuggingFace\"])\n",
    "demo.launch(share=True, server_port=int(os.environ['PORT3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64edd474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 30\u001b[0m\n\u001b[0;32m     21\u001b[0m gr\u001b[39m.\u001b[39mclose_all()\n\u001b[0;32m     22\u001b[0m demo \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mInterface(fn\u001b[39m=\u001b[39mner,\n\u001b[0;32m     23\u001b[0m                     inputs\u001b[39m=\u001b[39m[gr\u001b[39m.\u001b[39mTextbox(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mText to find entities\u001b[39m\u001b[39m\"\u001b[39m, lines\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)],\n\u001b[0;32m     24\u001b[0m                     outputs\u001b[39m=\u001b[39m[gr\u001b[39m.\u001b[39mHighlightedText(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mText with entities\u001b[39m\u001b[39m\"\u001b[39m)],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m                     allow_flagging\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnever\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m                     examples\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mMy name is Andrew, I\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm building DeeplearningAI and I live in California\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMy name is Poli, I live in Vienna and work at HuggingFace\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> 30\u001b[0m demo\u001b[39m.\u001b[39mlaunch(share\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, server_port\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mPORT4\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if merged_tokens and token['entity'].startswith('I-') and merged_tokens[-1]['entity'].endswith(token['entity'][2:]):\n",
    "            # If current token continues the entity of the last one, merge them\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token['word'] += token['word'].replace('##', '')\n",
    "            last_token['end'] = token['end']\n",
    "            last_token['score'] = (last_token['score'] + token['score']) / 2\n",
    "        else:\n",
    "            # Otherwise, add the token to the list\n",
    "            merged_tokens.append(token)\n",
    "\n",
    "    return merged_tokens\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input, parameters=None, ENDPOINT_URL=API_URL)\n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=ner,\n",
    "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "                    title=\"NER with dslim/bert-base-NER\",\n",
    "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"My name is Andrew, I'm building DeeplearningAI and I live in California\", \"My name is Poli, I live in Vienna and work at HuggingFace\"])\n",
    "\n",
    "demo.launch(share=True, server_port=int(os.environ['PORT4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
